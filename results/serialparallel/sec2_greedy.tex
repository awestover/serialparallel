\section{A Deterministic Scheduling Algorithm}
In this section we present a simple deterministic scheduling
algorithm that does not use preemption. We show that this
algorithm is $2$-competitive with OPT.

First we note that without loss of generality we may consider
TAPs where the cost ratio $\pi(\tau)/\sigma(\tau)$ for any task
$\tau$ is in $[1,p]$; if $\pi(\tau)/\sigma(\tau) < 1$, i.e. the
parallel implementation has lower work than the serial
implementation, then the scheduler clearly should never use the
serial implementation of this algorithm, so we can replace the
serial implementation with the parallel implementation and hence
get cost ratio $1$, similarly, if $\pi(\tau)/\sigma(\tau) > p$
then the scheduler should never run the parallel task and we can
replace the parallel implementation of the task with the serial
implementation to get cost ratio $p$.

We say that a time is a \defn{verge} time for our algorithm if at
this time no processors are performing tasks and there is at
least one ready task.

We propose Algorithm~\ref{alg:gr}, which we call \defn{GR}
(GR is short for \enquote{greedy}), as a scheduling algorithm.

\begin{algorithm}
  \caption{GR}
  \label{alg:gr}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State do what OPT would do in the case where no tasks arrive later than
        this verge time in the TAP 
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

GR is an incredibly simple algorithm, although there is some
hidden complexity in it: the algorithm is consulting an oracle to
know what OPT would do, albeit in the relatively simple special
case of where all the tasks arrive at the same time. In
Corollary~\ref{cor:one_round_OPT_oracle} we exhibit an oracle
that yields a schedule that achieves the same awake time as OPT
for TAPs where all the tasks arrive at a single time, hence
showing that GR actually can be computed. First we analyze the
competitive ratio of GR assuming the existence of such an oracle. 

Consider a TAP $\mathcal{T}$. Let $\ell$ be the number of verge
times for $\mathcal{T}$; note that $\ell \le n$ which in
particular is finite. Let $t_i$ be the $i$-th time that is a
verge time, let $q_i$ be the number of ready tasks for GR at
time $t_i$. Let $T^{ALG}(q_1, \ldots, q_{\ell'})$ denote the
awake time of a scheduling algorithm ALG on the truncation of the
TAP $\mathcal{T}$ that only consists of tasks arriving at times
before $t_{\ell'}$.

By construction we have
\begin{equation}
  \label{eq:same_single}
  T^{OPT}(q) = T^{GR}(q).
\end{equation}
We remark GR \enquote{locally} schedules optimally, which is why
we refer to GR as \enquote{greedy}. 

An ALG-gap is an interval of time of non-zero length where for
all times in the interior of the interval ALG has completed every
task that has arrived thus far. Additionally for an interval to
be an ALG-gap the interval must contain no other intervals which
are also ALG-gaps (i.e. it is a \enquote{maximal} interval
satisfying our conditions).
We say that a TAP is \defn{ALG-gap-free} if it contains no ALG-gaps.

Now we prove an important property of OPT.
\begin{claim}
  \label{clm:OPT_finishes_first}
  If there is a scheduling algorithm ALG that completes all tasks by
  time $t_*$ then OPT finishes all tasks by time $t_*$.
\end{claim}
\begin{proof}
  Say that ALG completes all tasks by time $t_*$. Let $t_0 < t_*$
  be the most recent time that OPT has completed all tasks that
  arrive before time $t_0$. If OPT has not finished all tasks by
  time $t_*$ then it was acting sub-optimally, as it could steal
  the strategy that ALG used on $[t_0, t_*]$ to achieve lower
  awake time. In particular, for any tasks that arrive in $[t_0,
  t_*]$ OPT could schedule them as ALG schedules them. We remark
  that OPT should not steal all of ALG. 
\end{proof}
Note that as an immediate consequence of Claim~\ref{clm:OPT_finishes_first}
we have that any ALG-gap is a subset of an OPT-gap.

Decomposing TAPs into gap-free subsets of the TAP is very useful.
Part of the reason for this is the following fact:
\begin{claim}
  \label{clm:just_consider_gapless}
  If an algorithm ALG achieves competitive ratio $r$ on
  ALG-gap-free TAPs, then ALG achieves 
  competitive ratio $r$ on arbitrary TAPs.
\end{claim}
\begin{proof}
  We partition the tasks based on arrival time, splitting the
  tasks on the ALG-gaps. That is, we split the tasks into groups
  so that two tasks $\tau_i, \tau_j$ are in the same group if and
  only if there are no gaps in between the arrival times of
  $\tau_i$ and $\tau_j$.
  We can define an interval of time $I_i$ for each of these
  ALG-gap-free subsets of the TAP, where $I_i$ is defined so that
  all tasks in the $i$-th group start and finish at times
  contained in the interval $I_i$.

  Let $T_{I_i}^{OPT}$ and $T_{I_i}^{ALG}$ denote the awake time
  of OPT and ALG on interval $I_i$. Because $I_i$ is ALG-gap-free
  we have $T^{ALG} = \sum_{i} T^{ALG}_{I_i}$.
  Further, recall that by Claim~\ref{clm:OPT_finishes_first} any
  ALG-gap is also an OPT-gap, so
  $T^{OPT} = \sum_{i} T_{I_i}^{OPT}$. 
  Hence from our assumption that ALG is $r$-competitive on
  gap-free TAPs, such as the subset of the TAP on the interval
  $I_i$, we have $T_{I_i}^{ALG} \le r\cdot T_{I_i}^{OPT}$ for
  all $i$. Summing we get $T^{ALG} \le r\cdot T^{OPT}$, as desired.
  
\end{proof}

By Claim~\ref{clm:just_consider_gapless}, in order to bound GR's
competitive ratio, it suffices to consider TAPs
without GR-gaps. Note however that a TAP without
GR-gaps could still have OPT-gaps.

We conclude our analysis of the competitive ratio of GR in
Proposition~\ref{prop:2competitive} with an inductive argument on
the number of OPT-gaps in the TAP.
First we establish the base case for the argument: we consider
GR's competitive ratio on a TAP without OPT-gaps.  

\begin{claim}
  \label{clm:no_optgaps}
  GR is $2$-competitive on any OPT-gap-free TAP.
\end{claim}
\begin{proof}
  Since the TAP is OPT-gap-free we must have
  \begin{equation}
    \label{eq:opt_isnt_so_much_better}
    T^{OPT}(q_1, \ldots, q_{\ell}) \ge T^{SGR}(q_1, \ldots, q_{\ell-1}).
  \end{equation}
  Because GR finishes all $q_{i}$ tasks that arrive at time $t_i$
  by time $t_{i+1}$ we can actually always decompose
  $T^{GR}(q_1, \ldots, q_\ell)$ as 
  \begin{equation}
    \label{eq:decomposeGR}
    T^{GR}(q_1, \ldots, q_\ell) = \sum_{i=1}^\ell T^{GR}(q_i).
  \end{equation}
  By Equation~\eqref{eq:decomposeGR}, and
  Equation~\eqref{eq:same_single} we thus have 
  \begin{equation}
    \label{eq:decompose_rearanged}
    T^{GR}(q_1, \ldots, q_\ell) = T^{GR}(q_1, \ldots, q_{\ell-1}) + T^{OPT}(q_\ell).
  \end{equation}

  Hence by Equation~\eqref{eq:opt_isnt_so_much_better} and
  Equation~\eqref{eq:decompose_rearanged} we have
  \begin{align*}
    T^{GR}(q_1, \ldots, q_\ell) &\le T^{OPT}(q_1, \ldots, q_\ell) + T^{OPT}(q_\ell)\\
                                   &\le 2T^{OPT}(q_1, \ldots, q_\ell),
  \end{align*}
  as desired.
\end{proof}

\begin{proposition}
  \label{prop:2competitive}
  GR is $2$-competitive.
\end{proposition}
\begin{proof}
  The proof is by strong induction on the number of OPT-gaps. 
  The base case of our induction is established in
  Claim~\ref{clm:no_optgaps}, which says that if there are $0$
  OPT-gaps then GR is $2$-competitive. 

  Consider a TAP that has more than $0$ OPT gaps;
  say that its first OPT-gap starts at time $t_*$.
  Let $j$ be the largest index such that verge time $t_j <
  t_*$.

  Using our inductive hypothesis we have:
  \begin{align*}
  &T^{OPT}(q_1, \ldots, q_\ell) \\
  &\ge T^{OPT}(q_1, \ldots, q_j) + T^{OPT}(q_{j+1}, \ldots, q_{\ell})\\
  &\ge \frac{1}{2}\paren{T^{GR}(q_1, \ldots, q_j) + T^{GR}(q_{j+1}, \ldots, q_{\ell})}\\
  &=\frac{1}{2} T^{GR}(q_1, \ldots, q_\ell).
  \end{align*}

\end{proof}

Now we demonstrate the existence of an oracle computing OPT on
TAPs where all tasks arrive at a single point in time.
First, we need a lemma:
\begin{lemma}[Cake frosting lemma]
  you can frost a cake
\end{lemma}
\begin{proof}
  Of course by Claim~\ref{clm:sgr_single} $T^{OPT}(q) \le
  T^{SGR}(q) = T(q)$. We now claim that OPT can do no better than
  this. This is obvious if $q \le p$: if OPT schedules any task
  in serial then OPT has awake time at least $1$, and if OPT
  schedules everything in parallel then OPT has awake time at
  least $qk/p$; for $q\le p$ we have $T(q) = \min(1, qk/p)$, so
  OPT can do no better than SGR here. It is intuitively obvious
  that if there are $q> p$ tasks, then scheduling about
  $\floor{q/p}$ tasks in serial to each processor like SGR does
  is the right strategy; proving this is somewhat intricate
  however.

  Say OPT schedules $x$ of the $q$ tasks in serial, and
  schedules the remaining $q-x$ in parallel.
  Say that an optimal assignment of the tasks, under the constraint
  that $x$ of the tasks are scheduled in serial and $q-x$ are
  scheduled in parallel, achieves awake time $M$.

  We claim that there must exist an optimal assignment of tasks
  such that each processor is assigned either $\floor{x/p}$ or
  $\ceil{x/p}$ serial tasks. To prove this, we start from some
  optimal assignment, and modify it in such a way as to make the
  configuration \enquote{closer} to our desired configuration.
  Let $n_\sigma(\rho_i)$ be the number of serial tasks scheduled
  on processor $\rho_i$.

  To formalize a notion of \enquote{closeness} we define a potential 
  function $\phi$ of the assignment $S$ of tasks:
  $$\phi(S) = \sum_{i} \min(|n_\sigma(\rho_i)-\floor{x/p}|, |n_\sigma(\rho_i)-\ceil{x/p}|.$$ 
  Note that $\phi(S)$ is non-negative. We desire a configuration with $\phi(S) = 0$.
  Consider a configuration of tasks achieving awake time $M$ with $\phi(S) > 0$.
  We first apply the following procedure to the configuration:
  while the difference between the maximum work assigned to a
  processor and the minimum work assigned to a processor is more
  than $1$ swap $1$ unit of work from a processor with the
  maximum amount of work to a processor with the minimum amount
  of work. This swap cannot increase the range of works assigned
  to processors, and the process must eventually terminate.
  Now, while $\phi(S) > 0$ there must 
  exists $\rho_i, \rho_j$ with $n_\sigma(\rho_i) < \floor{x/p}$
  and $n_\sigma(\rho_j) > \floor{x/p}$ or there exists $\rho_i,
  \rho_j$ with $n_\sigma(\rho_i) < \ceil{x/p}$ and
  $n_\sigma(\rho_j) > \ceil{x/p}$. By construction the range of
  the works is at most $1$; hence $\rho_i$ has at least $1$ unit
  of parallel work to have work within $1$ of $\rho_j$ despite
  having at least $2$ fewer serial tasks than $\rho_j$. Then
  $\rho_i$ gives this $1$ unit of parallel work to $\rho_j$, and
  in exchange $\rho_j$ gives $\rho_i$ a serial task. This
  swapping operation decreases $\phi(S)$ by exactly $1$, and does
  not change the amount of work assigned to each processor, which
  importantly means that the swap does not increase the range of
  the works. Hence, we can repeat this swapping process to
  eventually achieve a configuration with awake time $M$ where each 
  processor has $\floor{x/p}$ or $\ceil{x/p}$ serial tasks.

  If $x\bmod p = 0$ then the awake time of OPT is clearly at
  least 
  \begin{equation} \label{eq:case_xmodp0}
    x/p + (q-x)k/p.
  \end{equation}
  Note that if $x$ increases by $p$ then \eqref{eq:case_xmodp0}
  changes by $1-k < 0$. That is, \eqref{eq:case_xmodp0} is
  monotonically decreasing in $x$, and is thus minimized by
  setting $x = p\floor{q/p}$ and hence getting $q-x = q\bmod p$.
  This gives awake time $\floor{q/p} + (q\bmod p)k/p \ge T(q)$.

  Now we consider the case where $x\bmod p \neq 0$. Here $(p -
  (x\bmod p))/k$ tasks can be added in serial without
  increasing the work at all. Thus the awake time is at least
  \begin{equation} \label{eq:case_xmodpnot0}
    \ceil{x/p} + \frac{k}{p}\paren{\max\paren{0, q-x - \frac{p-(x\bmod p)}{k}}}.
  \end{equation}

  Consider when the $\max$ in \eqref{eq:case_xmodpnot0} yields $0$. 
  For this to happen we must have
  $$q-x \le \frac{p-x\bmod p}{k}.$$
  As $p-x\bmod p \le p$ we get the following bound on $q-x$:
  $$q-x \le p/k,$$
  which must be met in order for the $\max$ to yield $0$.
  Clearly as $q \ge x \ge q-p/k$, $\floor{x/p} \ge \floor{q/p}-1$; we
  claim that this inequality is actually strict. Imagine that
  $\floor{x/p} = \floor{q/p}-1$. Because the $\max$ expression
  yields $0$, meaning that the parallel tasks add nothing to the
  awake time, if all processors only have $\floor{q/p}-1$ or
  $\floor{q/p} < q/p$ serial tasks, then the total work is at
  most $\floor{q/p} < q/p$ which is impossible: the total work in
  the system must be at least $q$ and it can be distributed in
  the best case perfectly equally which makes $q/p$ as a lower
  bound on the time to complete $q$ tasks. Hence $\floor{x/p} = \floor{q/p}$. 
  But then the awake time is at least $\ceil{x/p} = \floor{q/p} + 1 \ge T(q)$.

  Now we consider the case when the $\max$ in
  \eqref{eq:case_xmodpnot0} yields some positive number.
  Note that if $x$ increases by $p$ (but $x$ is still
  sufficiently small so that the $\max$ yields a positive number)
  then \eqref{eq:case_xmodpnot0} changes by $1-k < 0$.
  Further, if $x$ increases by $1$ (but $x$ is still
  sufficiently small so that the $\max$ yields a positive number) without $\ceil{x/p}$
  changing, then \eqref{eq:case_xmodpnot0} changes by $(k/p)(1/k
  -1) < 0$. That is, \eqref{eq:case_xmodpnot0} is monotonically
  decreasing in $x$. Hence we still have that the awake time is at least $T(q).$

  We have considered all cases, and shown that no matter what
  choice of $x$ OPT makes, and no matter how OPT schedules given
  that choice of $x$, OPT must incur awake time at least $T(q)$,
  as desired.
\end{proof}


\begin{algorithm}
  \caption{OPT Oracle}
  \label{alg:opt_oracle}
  \begin{algorithmic}
    \State $\text{minAwakeTime} \gets \infty$
    \For{$I \in \{0,1\}^n$} 
      \If{$I_i = 1$}
        \State Schedule task $i$ in parallel when it arrives
      \Else
        \State Schedule task $i$ in serial when it arrives
      \EndIf
      \State In particular, first schedule serial tasks to minimize awake time
      \State And then sprinkle parallel tasks on top 

      \If{$\text{awakeTime}_I \le \text{minAwakeTime}$}
        \State{$\text{minAwakeTime} \gets \text{awakeTime}_I$}
      \EndIf
    \EndFor
  \end{algorithmic}
\end{algorithm}

\begin{corollary}
  OPT Oracle is an oracle for OPT.
\end{corollary}
\begin{proof}
  
\end{proof}

