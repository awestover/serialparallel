\section{Lower Bounds}

In this section we prove several impossibility results, which
show that we cannot hope to substantially improve our algorithms.

\subsection{Deterministic Algorithms for Minimizing Awake Time}
It is clear that GR is not $(2-\epsilon)$-competitive for any
$\epsilon > 0$. We might hope to achieve a
$(1+\epsilon)$-competitive scheduling algorithm for this problem.
However, in this subsection we establish that it is impossible
for an off-line deterministic scheduler to get a competitive
ratio lower than $1.25$, even using preemption. That is, we show
that for any deterministic algorithm ALG there is some input on
which ALG has awake time at least $1.25$ times greater than OPT. 

In Table~\ref{tab:lowerboundFork1} and
Table~\ref{tab:lowerboundFork2} we specify two sets of tasks.
For each time we give a list of which tasks arrive in the format
$(\sigma, \pi)\times m$ where $\sigma, \pi$ are the serial and
parallel works of a task and $m$ is how many of this type of task
arrive at this time.

\begin{table}[H]
\caption{}
\label{tab:lowerboundFork1}
\centering
\begin{tabular}{|l|l|}
\hline
time & tasks                    \\ \hline
$0$  & $(4, 2p) \times 1$       \\ \hline
$1$  & $(3, 3p) \times (p-1)$ \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\caption{}
\label{tab:lowerboundFork2}
\centering
\begin{tabular}{|l|l|}
\hline
time & tasks                    \\ \hline
$0$  & $(4, 2p) \times 1$       \\ \hline
\end{tabular}
\end{table}

Consider an arbitrary deterministic scheduling algorithm. If at
time $0$ the arriving tasks are $(4, 2p)\times 1$ (i.e. a single
task arrives, with serial work $4$ and parallel work $2p$) then
the scheduler has two options: it can schedule this task in
serial, or in parallel.

If no further tasks arrive, i.e. the task schedule is from
Table~\ref{tab:lowerboundFork2} then OPT would have awake time
$2$ by distributing the tasks work equally amongst all
processors, whereas a scheduler that ran the task in serial for
all of the time that it was running the task during the first
second after the task arrived would have awake time at least $3$.
In this case the competitive ratio of the algorithm is at least $1.5$.

On the other hand, the algorithm could decide to not run the task
in serial for any time during the first second after the task
arrives. In this case, if
and it turns out that the task schedule is from
Table~\ref{tab:lowerboundFork1}, then the algorithm has again
acted sub-optimally. In particular, for the schedule given in
Table~\ref{tab:lowerboundFork1}, OPT schedules the task that
arrives at time $0$ in serial, and then schedules all the tasks
that arrive at time $1$ in serial as well, and hence achieves
awake time $4$. On the other hand, the awake time of an algorithm
that did not schedule the task that arrived at time $0$ in
serial is at least $5$: such a scheduler may either choose at
time $1$ to cancel the task from time $0$ and run it in serial,
or the scheduler may choose to let the parallel implementation
finish running. In this case the competitive ratio of the
algorithm is $5/4$.

Hence it is impossible for any deterministic algorithm to achieve
a competitive ratio of lower than $1.25$.

We remark that the numbers in this argument can clearly be
optimized, to give an improved lower bound of about $1.36$ on
competitive ratio. As this is asymptotically not interesting, and
much messier, we decide to not give this better argument.

\subsection{Randomized Algorithms For Minimizing Awake Time}
We might that there is a randomized algorithm that gets a
competitive ratio substantially better than any deterministic
algorithm can, for example maybe there is a randomized algorithm
that is $(1+\epsilon)$-competitive on any input with high
probability, or a randomized algorithm with expected competitive
ratio at most $(1+\epsilon)$ on any input. However, in this
subsection we show that this is impossible.

In particular, we demonstrate a lower-bound of $1.0625$ on the
competitive ratio of any randomized off-line algorithm.

Recall the TAPs from Table~\ref{tab:lowerboundFork1} and
Table~\ref{tab:lowerboundFork2}; we will use these as sub-parts
of our the TAP that we build to be adversarial for a randomized
algorithm. 

Fix some off-line randomized algorithm RAND. We say that an input
TAP is \defn{bad} for RAND if with high probability RAND's awake
time on TAP is at least $1.0625$ times that of OPT.
We construct a class of TAPs, and show that some of the TAPs in
this class must be bad for RAND.

Let $\mathcal{T}_{I}$, for some some binary string $I$, be the
TAP consisting of the TAP from Table~\ref{tab:lowerboundFork1} at
time $10i$ if $I_i = 1$ and the TAP from
Table~\ref{tab:lowerboundFork2} if $I_i = 0$. 

Consider a $I$ chosen uniformly at random from $\{0,1\}^m$ for
some parameter $m$.
On each sub-tap RAND has at most a $1/2$ chance of acting as OPT
does, and at least a $1/2$ chance of acting sub-optimally, in
particular, from our analysis above showing that any deterministic
algorithm has competitive ratio at least $1.25$ on at least one
of these inputs, RAND has at least a $1/2$ chance of this
happening.
By a Chernoff Bound, with probability at least
$1-e^{-\Omega(m)}$, on at least $1/4$ of the sub-taps RAND has
competitive ratio at least $1.25$. Since there is no overlap, by
design, of the sub-taps (by spacing them out), this means that
overall the competitive ratio of RAND is at least $1\cdot 3/4 +
1.25 \cdot 1/4 = 1.0625.$

Note that the number of tasks in such a TAP is less than $mp$, so
$n \le mp$, and thus $m \ge n/p$.
Hence our result that holds with high probability in $m$ holds
with high probability in $n/p$ too.
Of course $n\gg p$ so this is pretty decent.

Because a randomly chosen TAP from this class of TAPs is bad for
RAND with high probability in $n/p$, by the probabilistic method
there is at least one TAP in this class of TAPs that is bad for
RAND. 

\subsection{Preemption is necessary for Minimizing Mean Response Time}

Consider a deterministic scheduling algorithm ALG that does not
use preemption. Say that the $\max$ number of processors given
work over all input TAPs is $p_0$. We claim that there is some
input TAP on which ALG does arbitrarily poorly compared to OPT in
terms of mean response time.
Consider a sequence of tasks that forces ALG to have $p_0$
processors in use, and let $h_0$ be the minimum amount of work on
any processor with work. Say we have sent $n_0$ tasks so far.
We choose $n$ such that $n_0 = \epsilon n$, and now we send
$(1-\epsilon)n$ tasks each with work $h_0/2$. OPT is presumably
going to be preempting stuff to run these, so our competitive
ratio is basically $\Theta(n)$, which is in particular trash.


