\documentclass[twocolumn]{article}[11pt]
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{csquotes} 

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

\newcommand{\defn}[1]{{\textit{\textbf{\boldmath #1}}}\xspace}
\renewcommand{\paragraph}[1]{\vspace{0.09in}\noindent{\bf \boldmath #1.}} 

\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode} % adding [noend] deletes the end while and stuff

\usepackage[capitalise,nameinlink,noabbrev]{cleveref}
\crefname{equation}{}{} % cref{eq:blah} only does (1) instead of Equation (1)
\crefname{enumi}{Step}{} % cref{eq:blah} only does (1) instead of Equation (1)

\newtheorem{fact}{Fact}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem{clm}{Claim}
\newtheorem{claim}{Claim}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}

\author{Alek Westover}
\title{Serial-Parallel Scheduling Problem}

\begin{document}
\maketitle

\begin{abstract}
  There are many problems for which the best parallel algorithms
  have larger cost than the best serial algorithms. 
  We consider a scheduler that is receiving many tasks with
  serial and parallel implementations that have potentially
  different costs. The scheduler can choose whether to run each
  task in serial or in parallel.
  The scheduler aims to minimize the total time that it has
  unfinished tasks. We analyze the competitive-ratio of
  schedulers, i.e. the ratio of the time of a scheduler to the
  optimal time.

  We exhibit a scheduler that is $2$-competitive for the
  symmetric-task case of this problem, a scheduler that is
  $4$-competitive for the symmetric-cost-ratio case of this
  problem, and an algorithm that is $8$-competitive for the
  general case of this problem.

  We prove that no deterministic scheduler can have a competitive
  ratio smaller than $2$.

  We also exhibit a randomized scheduler that achieves
  expected competitive ratio at least $1.5$.

  Also, we look at the problem when the tasks are allowed to do
  recursion, i.e. they can spawn multiple tasks.

\end{abstract}

\section{Introduction}
A parallel algorithm is said to be \defn{work-efficient} if the
work of the parallel algorithm is the same as the work of a
serial algorithm for the same problem. Most implementations of
parallel algorithms are not work-efficient, often having work
that is a constant factor greater, or even asymptotically
greater, than the work of the serial algorithm for the problem.

In the \defn{Serial-Parallel Scheduling Problem} we have to
perform $n$ tasks $\tau_1, \ldots, \tau_n$ ($n$ unknown ahead of
time). We have $p$ processors $\rho_1, \ldots, \rho_p$. Each task
$\tau_i$ has a parallel implementation with work $\pi(\tau_i)$ and a
serial implementation with work $\sigma(\tau_i)$. The tasks will become
available at some times $t(\tau_1), \ldots, t(\tau_n)$. 
The sequence of tasks with their associated parallel and serial
implementations works and with their associated arrival times is
called a \defn{task arrival plan}.
The scheduler maintains a set of \defn{ready} tasks, which are tasks that have
become available but are not currently being run on any
processor. At time $t(\tau_i)$ task $\tau_i$ is added to the set of
ready tasks. At any time the scheduler can decide to schedule
some ready task, and can choose whether to run the task in
serial, in which case the scheduler must choose a single
processor to run the task on, or the scheduler can choose to run
the task in parallel, in which case the scheduler can distribute
the tasks work arbitrarily among the processors. Intuitively, if
there are many ready tasks then the scheduler should run the
serial implementations of the tasks because the scheduler can
achieve parallelism across the tasks. On the other hand, if there
are not very many ready tasks it is probably better for the
scheduler to run the parallel versions of the tasks --- even
though they are possibly not work efficient, i.e. $\pi(\tau) >
\sigma(\tau)$ --- because by so doing at least the scheduler can
achieve parallelism within tasks.

Let the \defn{awake time} of the scheduler be the duration of
time over which the scheduler has unfinished tasks.
The scheduler attempts to minimize awake time.

We measure how well the scheduler is able to minimize its awake
time by comparing its awake time to the awake time of the optimal
strategy, which we will denote OPT. Note that OPT is able to see
the whole sequence of tasks in advance.
The \defn{competitive ratio} of a scheduler is the ratio
of its awake time to the awake time of OPT on the same input.

\section{Deterministic Scheduling Algorithms}

In this section we exhibit three scheduling algorithms that
guarantee small competitive ratios. We start with looking at
special cases of the game, and build on the strategies from the
special cases to get algorithms that work in more general
settings.

\subsection{Symmetric-Tasks Case}
\label{subsec:symmetrictasks}
First we consider a special case of the problem: the case where
all tasks have identical serial and parallel works. Let
the work of the serial implementations be $1$, and let the work
of the parallel implementations be $k \in [1, p]$\footnote{Note that
without loss of generality $k \in [1,p]$: if $k < 1$, i.e. the
parallel implementation has lower work than the serial
implementation, then the scheduler clearly should never use the serial
implementation of this algorithm, so we can replace the serial
implementation with the parallel implementation and hence get
$k=1$, similarly, if $k > p$ then the scheduler should never run
the parallel task and we can replace the parallel implementation
of the task with the serial implementation.}.

We say that a time is a \defn{verge} time if no processors are
performing tasks and there is at least one ready task.

{\color{red}
  CHILL0 is a better algorithm than CHILL, like as in strictly
  better, but CHILL is more convenient to analyze. There's just a
  nice bit of symmetry to CHILL that isn't present in CHILL0:
  CHILL finishes anything less than $p$ in a single valley
  interval. Anyways CHILL is nicer aesthetically and the proof
  works, so there. 
}

We propose Algorithm~\ref{alg:chill}, which we call \defn{CHILL},
for scheduling in the symmetric-tasks case.

\begin{algorithm}
  \caption{CHILL0}
  \label{alg:chill0}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State $q \gets $ number of ready tasks
        \If{$q \ge p/k$}
          \State schedule $\min(q, p)$ tasks in serial
          \State giving each processor at most $1$ task
        \Else
          \State schedule one task in parallel
          \State distributing its work equally 
        \EndIf
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{CHILL}
  \label{alg:chill}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State $q \gets $ number of ready tasks
        \If{$q \ge p/k$}
          \State schedule $\min(q, p)$ tasks in serial
          \State giving each processor at most $1$ task
        \Else
          \State schedule $q$ tasks in parallel
          \State distributing work equally 
        \EndIf
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

Before analyzing CHILL we need a little claim: 
\begin{clm}
  \label{clm:optfinishesbeforeyou}
  If there is a scheduling algorithm that completes all tasks by
  time $t_*$ then OPT finishes all tasks by time $t_*$.
\end{clm}
\begin{proof}
  Let $t_0 < t_*$ be the most recent time that OPT had no work.
  If OPT has work at time $t_*$ then it was acting sub-optimally,
  and should steal the strategy of whatever other scheduling
  algorithm was able to complete all of its work by time $t_*$
  for use in the interval of time $[t_0, t_*]$.
\end{proof}

We prove the following regarding CHILL:
\begin{proposition}
  \label{prop:2competitive}
  CHILL is 2-competitive with OPT in the symmetric-tasks case of
  the Serial-Parallel Scheduling Problem. 
\end{proposition}
\begin{proof}
  Let $v$ be the number of verge times; note that $v\le n$ which
  in particular is finite. Let $t_i$ be the $i$-th time that is a
  verge time, let $q_i$ be the number of ready tasks at time
  $t_i$, let $\Delta_i t = t_{i+1} - t_i$, let $\Delta_i q =
  q_{i+1} - q_i$. Define $t_0 = -\infty, t_{v+1} = +\infty$; 
  these are not verge times, but are merely defined for convenience.
  We call the interval $(t_i, t_{i+1})$ for $i\in \{0,1,\ldots,
  v\}$ \defn{valley interval $i$}. 

  Let $T^{OPT}(q_1, \ldots, q_{v'})$ and $T^{CHILL}(q_1, \ldots,
  q_{v'})$ denote the awake time of OPT and CHILL respectively on
  the truncation of the task arrival plan that only consists of
  tasks arriving at times before verge time $t_{v'}$ where the
  task arrival plan is such that CHILL has $q_i$ ready tasks at verge
  time $t_i$ for all $i \le v'$. Let 
  $$ T(q) = \floor{q/p} + \min(1, (q\bmod p)\cdot k/p). $$

  \begin{clm}
    $$T(q) = T^{OPT}(q) = T^{CHILL}(q).$$
  \end{clm}
  \begin{proof}
    If work only arrives before a single verge time, then all the
    work arrives at the same time. 

    CHILL first schedules $p$ tasks in serial for $\floor{q/p}$
    verge times, which takes time $1\cdot \floor{q/p}$. Then on
    the final verge time CHILL either schedules $q\bmod p$ tasks
    in serial, which takes time $1$, or schedules $q\bmod p$
    tasks in parallel, which takes time $(q\bmod p)k/p$; in
    particular CHILL chooses whichever of these options leads to
    lower awake time. Hence overall on this task arrival plan
    CHILL achieves awake time $T(q)$.

    We now claim that OPT can do no better than this. This is clear.
    We remark that in this sense CHILL is greedy: it
    \enquote{locally} schedules optimally. 

  \end{proof}


  In proving Proposition~\ref{prop:2competitive} we only need to
  consider the case where there are no \defn{gaps}
  in the $t_i$'s --- intervals of time on which all ready tasks
  have already been completed  by CHILL --- i.e. where $\Delta_i t$ is always
  either $q_i k/p$ if at time $t_i$ $q_i$ tasks where scheduled in
  parallel or $1$ if at time $t_i$ some tasks are scheduled in
  serial. Considering such a case suffices because if there is a
  task sequence with gaps in it then we can decompose it into
  subsets without gaps, and we can analyze each of these segments
  separately because by Claim~\ref{clm:optfinishesbeforeyou} if
  CHILL finishes all its tasks by some time, then so does OPT, so
  the gaps for CHILL are gaps for OPT as well. 

  \begin{clm}
    \label{clm:l=0}
   If $\ell = 0$, meaning that there is exactly one time when work
  arrives, then CHILL achieves the same awake time as OPT. 
  That is, 
  $$T_0^{CHILL} = T_0^{OPT} \le 2T_0^{OPT}.$$
  \end{clm}
  \begin{proof}
  We consider cases on $q_1$. 

  If $q_1 < p/k$ OPT and CHILL both choose to schedule every task
  in parallel distributing work equally, and they thus both
  attain awake time $q_1 k/p$.

  If $p/k \le q_1 \le p$ both CHILL and OPT achieve awake time
  $1$ by scheduling all tasks in serial (except maybe when $q_1 =
  p/k$ OPT schedules all tasks in parallel, which still achieves
  awake time $1$). 

  If $q_1 > p$, then both OPT and CHILL will
  spend time $\floor{q_1/p}$ to reduce the number of unscheduled
  ready tasks to be below $p$, and then based on the value of
  $q_1\bmod p$ will either spend $1$ time to process the final
  group of tasks or time $(q_1\bmod p) k/p$ to process all the
  tasks (they choose whichever of these is smaller). 

  In summary, when $\ell=0$ CHILL achieves the exact same awake
  time as OPT, in particular awake time $T(q_1)$, although
  possibly with a slightly different schedule. We remark that in
  this sense CHILL is greedy: it \enquote{locally} schedules
  optimally. 
    
  \end{proof}

  \begin{clm}
    \label{clm:l=1}
    $$T_1^{CHILL} \le 2T_1^{OPT}.$$
  \end{clm}
  \begin{proof}
  We now consider $\ell=1$, meaning that some initial tasks come at
  some time, and then during valley interval $1$ some more tasks
  come. It may seem scary that new tasks can come in during the
  interval and the scheduler will not react to them until the end
  of the valley interval. In particular, one can imagine that the
  filler schedules some tasks in serial, and then immediately
  after the start of the valley interval more tasks arrive which
  could immediately be scheduled in serial by OPT, but will not
  be scheduled by CHILL until the end of the valley interval.
  However, if many tasks arrive during a valley interval, then
  the scheduler will be able to schedule many tasks during the
  next valley interval, which is good, and if few tasks arrive
  during the valley interval, then it doesn't really matter that
  they arrived. We now formalize this intuition. We again
  consider cases on $q_1$.

  $$T^{CHILL} = T(q_1) + T(q_2)$$
  $$T^{OPT} \ge T(q_1 + q_2)\ge \max(T(q_1), T(q_2))$$

  % In the case where $q_1 < p/k$ then CHILL schedules a task in
  % parallel, and then at time $t_2$ schedules optimally (by our
  % analysis of the case $\ell=1$). OPT could possibly do a tiny
  % bit better than this: if $q_2 > p/k$ then it is possibly
  % advantageous to schedule tasks in serial at time $t_1$.
  % However, in this case the ratio of their awake times is at
  % most $(T^{OPT} + k/p)/T^{OPT}$ which as $T^{OPT} \ge 1$ and
  % $k/p \le 1$ is less than $2$. On the other hand, if $q_2 < p/k$
  % then CHILL was actually acting optimally. 

  In the case where $q_1 < p/k$ then CHILL schedules $q_1$ tasks in
  parallel, and then at time $t_2$ schedules optimally (by our
  analysis of the case $\ell=1$). OPT could possibly do better
  than this: if $q_2 > p/k$ then it is possibly
  advantageous to schedule tasks in serial at time $t_1$.
  However, in this case the ratio of their awake times is at
  most $(T^{OPT} + q_1 k/p)/T^{OPT}$ which as $T^{OPT} \ge 1$ and
  $q_1 k/p \le 1$ is less than $2$. On the other hand, if $q_2 < p/k$
  then CHILL was actually acting optimally. 

  In the case where $q_1 \ge p/k$ then CHILL schedules $\min(q_1,
  p)$ tasks in serial at time $t_1$, and then schedules optimally
  starting from time $t_2$ (according to our analysis of the case
  $\ell=1$). The ratio of their awake times is at most
  $(T^{OPT}+1)/T^{OPT}$ which since $T^{OPT} \ge 1$ is at most
  $2$.

  Having analyzed both the case of large $q_1$ and small $q_1$ we have
  that $T_1^{CHILL} \le 2T_1^{OPT}$. 
  \end{proof}


  \begin{clm}
    \label{clm:inductivestep}
    Say that for some task arrival plan 
  $T_{\ell-1}^{CHILL} \le 2T_{\ell-1}^{OPT}$ and
  $T_\ell^{CHILL} \le 2T_\ell^{OPT}$. Then 
  $T_{\ell+1}^{CHILL} \le 2T_{\ell+1}^{OPT}$.
  \end{clm}
  \begin{proof}
    Basically without loss of generality $q_1, \Delta_1 q,
    \Delta_2 q \le p$ because these blocks of $p$ things may as
    well be handled the same way by OPT and CHILL. 

    This is immediately evident if $q_1 \ge p/k$ and $p/k \le q_2 \le p$,
    because in this case $T_{\ell+1}^{CHILL} = 2 + T_{\ell -1}^{CHILL}$
    and $T_{\ell+1}^{OPT} \ge 1 + T_{\ell-1}^{OPT}$ so
    $T_{\ell+1}^{CHILL} \le 2T_{\ell+1}^{OPT}$. 

    In fact even with just the assumption $q_1 \ge p/k$ the proof
    is clear, because in this case

    Basically here's how it goes:
    $T_{\ell+1}^{CHILL} = T_{\ell-1}^{CHILL} + \text{something
    for } \Delta_{\ell-1} q + \text{something for } \Delta_\ell q$

    $T_{\ell+1}^{OPT} \ge \min(T_{\ell-1}^{OPT} + \text{something
    for } \Delta_{\ell} q, T_{\ell}^{OPT} + \text{something for }
    \Delta_{\ell-1} q).$

    This works out to $T_{\ell+1}^{CHILL} \le 2T_{\ell+1}^{OPT}$.
  \end{proof}

  By (strong) induction on $\ell$ using Claim~\ref{clm:inductivestep} and the
  base cases of Claim~\ref{clm:l=0} and Claim~\ref{clm:l=1} we
  have that for any task arrival plan no matter what $\ell$
  is, $T_{\ell}^{CHILL} \le 2T_{\ell}^{OPT}$, as desired.

\end{proof}


\subsection{Symmetric-Cost-Ratios Case}
\label{subsec:symmetriccostratio}
Next we consider the case where there are different tasks with
implementations that have different works, but with the
restriction that the cost ratio of the parallel implementation to
the serial implementation is some fixed value $k$.

The ideas in this section were inspired by extremely elegant
analysis of an unrelated scheduling problem in \cite{bamboo20}.

Making a global definition of $1$ unit of work is now difficult
to do in a meaningful way, so we do not do this. Instead, at
every verge time we define locally $1$ unit of work to be the
work of the serial implementation of the task with the serial
implementation with the most work. 
Further, we partition the unscheduled ready tasks at a given verge time into
sets called \defn{level-$i$} sets based on the work of their serial
implementation: the level-$i$ set of tasks on a verge time is the
unscheduled ready tasks that have serial implementation's with
work in $[1/2^{i+1}, 1/2^{i}]$.
We now define a \defn{virtual-task} to be a collection of tasks.
The work of the serial and parallel implementations of a
virtual-task are the sums of the works of the serial and parallel
implementations of the virtual-tasks constituent tasks.

We propose Algorithm~\ref{alg:levelchill}, which we call \defn{LEVELCHILL},
for scheduling in the symmetric-cost-ratio case.

\begin{algorithm}
  \caption{LEVELCHILL}
  \label{alg:levelchill}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State Combine unscheduled ready tasks into virtual-tasks
        to maximize the number of level-$0$ virtual-tasks
        \State $q \gets $ number of virtual-tasks 
        \If{$q \ge p/k$}
          \State schedule $\min(q, p)$ virtual-tasks in serial
          \State giving each processor at most $1$ virtual-task
        \Else
          \State schedule a level-$0$ task in parallel
          \State distributing its work equally 
        \EndIf
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

We prove the following regarding LEVELCHILL:


\subsection{General Case}
Now we are ready to consider the general case, i.e. we place no
restrictions on the tasks in this Subsection.
We use the definitions from Subsection
\ref{subsec:symmetriccostratio} and Subsection
\ref{subsec:symmetrictasks}.
We propose Algorithm~\ref{alg:generalchill}, which we call
\defn{GENERALCHILL}.

\begin{algorithm}
  \caption{GENERALCHILL}
  \label{alg:generalchill}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State Combine unscheduled ready tasks into virtual-tasks
        to maximize the number of level-$0$ virtual-tasks
        \State $q \gets $ number of virtual-tasks 
        \If{$q \ge p/k$}
          \State schedule $\min(q, p)$ virtual-tasks in serial
          \State giving each processor at most $1$ virtual-task
        \Else
          \State schedule a level-$0$ task in parallel
          \State distributing its work equally 
        \EndIf
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

We claim the following regarding GENERALCHILL:
\begin{proposition}
  GENERALCHILL is $8$-competitive with OPT.
\end{proposition}
\begin{proof}
  eh, how bad could it possibly be
\end{proof}

\section{Lower-Bounds on Competitive Ratio}

In this section we establish that it is impossible for a
deterministic scheduler to get a competitive-ratio lower than
$2$. That is, we show that for any deterministic algorithm there
is some input on which OPT has awake time at most half of the
awake time of the deterministic scheduler.

Note that the competitive-ratio is trivially at least $1$.

In Table~\ref{tab:lowerboundFork1} and
Table~\ref{tab:lowerboundFork2} we specify two sets of tasks.
For each time we give a list of which tasks arrive in the format
$(\sigma, \pi)\times m$ where $\sigma, \pi$ are the serial and
parallel works of a task and $m$ is how many of this type of task
arrive at this time.

\begin{table}[H]
\caption{}
\label{tab:lowerboundFork1}
\centering
\begin{tabular}{|l|l|}
\hline
time & tasks                    \\ \hline
$0$  & $(4, 2p) \times 1$       \\ \hline
$1$  & $(3, 3p/2) \times (p-1)$ \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\caption{}
\label{tab:lowerboundFork2}
\centering
\begin{tabular}{|l|l|}
\hline
time & tasks                    \\ \hline
$0$  & $(4, 2p) \times 1$       \\ \hline
\end{tabular}
\end{table}

Consider an arbitrary deterministic scheduling algorithm. If at
time $0$ the arriving tasks are $(4, 2p)\times 1$ (i.e. a single
task arrives, with serial work $4$ and parallel work $2p$) then
the scheduler has two options: it can schedule this task in
serial, or in parallel.

If no further tasks arrive, i.e. the task schedule is from
Table~\ref{tab:lowerboundFork2} then OPT would have awake time
$2$ by distributing the tasks work equally amongst all
processors, whereas a scheduler that ran the task in serial would
have awake time $4$. In this case the competitive-ratio of the
algorithm is at least $2$.

On the other hand, the algorithm could decide to run the task in
parallel. If the algorithm decides to run the task in parallel,
and it turns out that the task schedule is from
Table~\ref{tab:lowerboundFork1}, then the algorithm has again
acted sub-optimally. In particular, for the schedule given in
Table~\ref{tab:lowerboundFork1}, OPT schedules the task that
arrives at time $0$ in serial, and then schedules all the tasks
that arrive at time $1$ in serial as well, and hence achieves
awake time $4$. On the other hand, the awake time of an algorithm
that did not schedule the task that arrived at time $0$ in
serial is at least $5$: such a scheduler may either choose at
time $1$ to cancel the task from time $0$ and run it in serial,
or the scheduler may choose to let the parallel implementation
finish running. In this case the competitive-ratio of the
algorithm is $5/4$.

Hence it is impossible for any deterministic algorithm in the
general case of the Serial-Parallel Scheduling Problem, or in
fact in the symmetric-cost-ratio case of the problem, to achieve
a competitive-ratio of lower than $1.25$.

By optimizing this argument a bit we can get a stronger
lower-bound of $1.44$ on the competitive-ratio (more
specifically, we can get a lower bound of the positive root of
the quadratic $x - 1/x = 3/4$ which is $(3+\sqrt{73})/8 \in
(1.44, 1.45)$).

{\color{red} TODO: do a completely different argument to get a
better bound. }

\section{Randomized Scheduling Algorithms}
Given a particular deterministic scheduling algorithm there will
be some inputs on which the algorithm will perform poorly. 
By employing randomization these worst case inputs can be
mitigated somewhat, at least in expectation.

We propose Algorithm~\ref{alg:randchill}, which we call
\defn{RANDCHILL}, for this case.

\begin{algorithm}
  \caption{RANDCHILL}
  \label{alg:randchill}
  \begin{algorithmic}
    \While{True}
      \If{verge time}
        \State sleep for a random amount of time, chosen
        uniformly at random from something, not really sure what 
        \State $q \gets $ number of ready tasks
        \If{$q \ge p/k$}
          \State schedule $\min(q, p)$ tasks in serial
          \State giving each processor at most $1$ task
        \Else
          \State schedule one task in parallel
          \State distributing its work equally 
        \EndIf
      \EndIf
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\begin{proposition}
  The expectation of RANDCHILL's competitive-ratio on any input
  is at least $1.5$.
\end{proposition}
\begin{proof}
 hmmm. 
\end{proof}


\section{Recursion}
First we must formalize this problem. Like what does
this even mean?

\section{Conclusions}
CHILL is a pretty good algorithm. 
An interesting question is: CHILL seems pretty dumb, why is it
so good then? I'm not totally sure.

\bibliographystyle{plain}
\bibliography{paper}

\end{document}
